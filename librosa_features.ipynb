{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"pKl_qFg7TC3F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675347108726,"user_tz":-330,"elapsed":23756,"user":{"displayName":"Pedro Hood","userId":"10030424054478699041"}},"outputId":"5ea725fd-4678-4afe-9753-18e26d71b254"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# MOUNTING DRIVE\n","# -------------------------------------->>>\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# IMPORTING LIBRARIES\n","# --------------------------------------->>>\n","\n","import glob\n","import pandas as pd\n","import librosa\n","import matplotlib.pyplot as plt\n","import librosa.display\n","from IPython.display import Image, display\n","import os, shutil\n","import cv2\n","from librosa import feature\n","import numpy as np"],"metadata":{"id":"dstpdWxATGzq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n","from tensorflow.keras.utils import load_img, img_to_array, image_dataset_from_directory\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Flatten\n","from numpy import expand_dims, save, load"],"metadata":{"id":"P-Rn897JkT8h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pre_model = VGG19(weights='imagenet', \n","                  input_shape=(224,224,3), \n","                  include_top=False\n","                  )"],"metadata":{"id":"uhnHqbaEkahy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675347119119,"user_tz":-330,"elapsed":5521,"user":{"displayName":"Pedro Hood","userId":"10030424054478699041"}},"outputId":"d72a919d-9156-47ff-97be-3cb98c1ebcb3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n","171446536/171446536 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"code","source":["for layer in pre_model.layers:\n","    layer.trainable = False"],"metadata":{"id":"JVVAnOwikeCN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential([\n","    pre_model,\n","    Flatten()]\n",")"],"metadata":{"id":"rt6ixKvGkfBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = \"audio_files\"\n","wav_files = glob.glob(path + \"/*.wav\")\n","\n","librosa_features = []\n","spectrogram = []\n","output = []\n","\n","for index, audio_path in enumerate(wav_files):\n","    \n","    file_name = os.path.basename(audio_path)\n","    y, sr = librosa.load(audio_path, duration=5)\n","    \n","    lbls = file_name.split('-')\n","    \n","    features = []\n","    \n","    # CHROMA STFT\n","    chroma_stft=librosa.feature.chroma_stft(y=y, sr=sr)\n","    features += [chroma_stft.mean(), chroma_stft.var()]\n","    \n","    # CHROMA CQT\n","    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n","    features += [chroma_cqt.mean(), chroma_cqt.var()]\n","\n","    # CHROMA CENS\n","    chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)\n","    features += [chroma_cens.mean(), chroma_cens.var()]\n","    \n","    # MFCCS\n","    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n","\n","    for i in range(len(mfccs)):\n","\n","        features += [mfccs[i].mean(), mfccs[i].var()]\n","\n","    # HARMONY AND PERCEPTR\n","    trim_y,_= librosa.effects.trim(y)\n","    y_harmonic, y_percep = librosa.effects.hpss(trim_y)\n","\n","    features += [y_harmonic.mean(), y_harmonic.var(), y_percep.mean(), y_percep.var()]\n","\n","    #RMS\n","    rms=librosa.feature.rms(y=y)\n","    features += [rms.mean(), rms.var()]\n","\n","    # SPECTRAL CENTROID\n","    cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n","    features += [cent.mean(), cent.var()]\n","\n","    # SPECTRAL BANDWIDTH\n","    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n","    features += [spec_bw.mean(), spec_bw.var()]\n","\n","    # SPECTRAL CONTRAST\n","    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n","    features += [contrast.mean(), contrast.var()]\n","\n","    # SPECTRAL FLATNESS\n","    flatness = librosa.feature.spectral_flatness(y=y)\n","    features += [flatness.mean(), flatness.var()]\n","\n","    # SPECTRAL ROLL OFF\n","    roll=librosa.feature.spectral_rolloff(y=y, sr=sr)\n","    features += [roll.mean(), roll.var()]\n","\n","    # TONNETZ\n","    tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n","    features += [tonnetz.mean(), tonnetz.var()]\n","\n","    # ZERO CROSSING RATE\n","    zcr=librosa.feature.zero_crossing_rate(y)\n","    features += [zcr.mean(), zcr.var()]\n","\n","    # ONSET DETECTION\n","    onset=librosa.onset.onset_detect(y=y, sr=sr, units='time')\n","    features += [onset.mean(), onset.var()]\n","\n","    # ONSET STRENGTH\n","    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n","    features += [onset_env.mean(), onset_env.var()]\n","\n","    # TEMPO AND BEATS\n","    tempo, beats = librosa.beat.beat_track(y=y, sr=sr)\n","    features += [tempo, beats.mean(), beats.var()]\n","\n","    features = np.array(features)\n","    \n","    librosa_features.append(features)\n","    \n","    features = []\n","    \n","    spectrogram_img = img_path = 'audio_imgs\\\\'+audio_path.split('\\\\')[1].split('.')[0]+'.png'\n","    \n","    img = load_img(spectrogram_img, target_size = (224,224))\n","    img = img_to_array(img)\n","    img = expand_dims(img, axis=0)\n","    img = preprocess_input(img)\n","    features = model.predict(img)[0].tolist()\n","\n","    lbls = file_name.split('-')\n","    features += [float(lbls[2])]\n","    features = np.array(features)\n","\n","    spectrogram.append(features)\n","    \n","    output.append(float(lbls[2]))\n","    \n","    print(index, \"done\")"],"metadata":{"id":"s5VV0KWAgzF-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save('/content/drive/Shareddrives/RAVEDESS/spectrogram.npy',DF)"],"metadata":{"id":"mJ12LVCqRZCg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls /content/drive/Shareddrives/RAVEDESS/RAVEDESS/ALL/new | grep \"(1).wav\"\n"],"metadata":{"id":"gk_qVUnF-rzJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mv \"03-01-02-02-02-02-12 (1).wav\" 03-01-02-02-02-02-12.wav"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DXnse-0lTswY","executionInfo":{"status":"ok","timestamp":1674723795647,"user_tz":-330,"elapsed":5,"user":{"displayName":"Pedro Hood","userId":"10030424054478699041"}},"outputId":"4d920c9a-ad5a-46b7-9066-8583a588ae8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mv: cannot stat '03-01-02-02-02-02-12 (1).wav': No such file or directory\n"]}]}]}