{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Importing libraries\n","!pip install git+https://github.com/tensorflow/docs\n","from absl import logging\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow_docs.vis import embed\n","import random\n","import re\n","import os\n","import tempfile\n","import ssl\n","import cv2\n","import numpy as np\n","import imageio\n","from IPython import display\n","from urllib import request\n","import re\n","import pprint\n","import glob\n","import pandas as pd\n","from IPython.display import Video"],"metadata":{"id":"K8ssChTIcbeD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673698519326,"user_tz":-330,"elapsed":28337,"user":{"displayName":"Avisha Singh","userId":"14873517839156421861"}},"outputId":"4bd2c97e-8fc1-4dc5-fc49-ec765a251f5b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/tensorflow/docs\n","  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-mnyzqmxu\n","  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-mnyzqmxu\n","  Resolved https://github.com/tensorflow/docs to commit 476e61b24de218a85fbd71edffdd314c3c6a8b61\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: astor in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (0.8.1)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (1.3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (2.11.3)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (5.7.1)\n","Requirement already satisfied: protobuf<3.20,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.19.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (6.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->tensorflow-docs==0.0.0.dev0) (2.0.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (4.3.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.1.2)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (2.16.2)\n","Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.8/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.7.1)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (0.19.3)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (5.10.2)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (22.2.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbformat->tensorflow-docs==0.0.0.dev0) (2.6.2)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (3.11.0)\n","Building wheels for collected packages: tensorflow-docs\n","  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0.dev0-py3-none-any.whl size=184468 sha256=095cbf701b41d1e8ca71923b05a65a7bb19479b24a48fe24a28d55c67ae6c712\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-uu2od3k_/wheels/3b/ee/a2/ab4d36a9a4af495bcb936f3e849d4b497b65fa40548a68d6c3\n","Successfully built tensorflow-docs\n","Installing collected packages: tensorflow-docs\n","Successfully installed tensorflow-docs-0.0.0.dev0\n"]}]},{"cell_type":"code","source":["# Mounting google drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"y4PCq8PDcyP-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673698541554,"user_tz":-330,"elapsed":22243,"user":{"displayName":"Avisha Singh","userId":"14873517839156421861"}},"outputId":"55dc8316-4614-4009-ab7a-2fbecc51e657"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["i3d = hub.load(\"https://tfhub.dev/deepmind/i3d-kinetics-600/1\").signatures['default']"],"metadata":{"id":"P6cCaqkmOIu0","executionInfo":{"status":"ok","timestamp":1673698545406,"user_tz":-330,"elapsed":3857,"user":{"displayName":"Avisha Singh","userId":"14873517839156421861"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Get the kinetics-600 action labels from the GitHub repository.\n","\n","with open('/content/drive/MyDrive/Scomp/Visual/Dataset/labels.txt') as f:\n","    l = f.readlines()\n","    labels=len(l)\n","\n","with open('/content/drive/MyDrive/Scomp/Visual/Dataset/labels.txt','r') as f_in:\n","    lines = f_in.read()\n","    listed=re.split('; |, |\\*|\\n',lines)\n","    pprint.pprint(listed)"],"metadata":{"id":"KpaUKuFoLUbQ","executionInfo":{"status":"error","timestamp":1673698545832,"user_tz":-330,"elapsed":433,"user":{"displayName":"Avisha Singh","userId":"14873517839156421861"}},"colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"f1ef935e-b8ec-4563-deb7-4b408368ffe5"},"execution_count":4,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-d7c34e6882f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get the kinetics-600 action labels from the GitHub repository.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Scomp/Visual/Dataset/labels.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Scomp/Visual/Dataset/labels.txt'"]}]},{"cell_type":"code","source":["def crop_center_square(frame):\n","  y, x = frame.shape[0:2]\n","  min_dim = min(y, x)\n","  start_x = (x // 2) - (min_dim // 2)\n","  start_y = (y // 2) - (min_dim // 2)\n","  return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]\n","\n","def load_video(path, max_frames=0, resize=(224, 224)):\n","  cap = cv2.VideoCapture(path)\n","  frames = []\n","  try:\n","    while True:\n","      ret, frame = cap.read()\n","      if not ret:\n","        break\n","      frame = crop_center_square(frame)\n","      frame = cv2.resize(frame, resize)\n","      frame = frame[:, :, [2, 1, 0]]\n","      frames.append(frame)\n","\n","      if len(frames) == max_frames:\n","        break\n","  finally:\n","    cap.release()\n","  return np.array(frames) / 255.0\n","def to_gif(images):\n","  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n","  imageio.mimsave('./animation.gif', converted_images, fps=25)\n","  return embed.embed_file('./animation.gif')"],"metadata":{"id":"FLYKcP_MI0cX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# HAPPY\n","\n","path = \"/content/drive/MyDrive/Scomp/Visual/Dataset/Youtube Data/Happy\"\n","wav_files = glob.glob(path + \"/*.mp4\")\n","for i in wav_files:\n","    \n","    video_path= i\n","    sample_video = load_video(video_path)[:100]\n","    sample_video.shape\n","\n","    def predict(sample_video):\n","      # Add a batch axis to the sample video.\n","      model_input = tf.constant(sample_video, dtype=tf.float32)[tf.newaxis, ...]\n","\n","      logits = i3d(model_input)['default'][0]\n","      probabilities = tf.nn.softmax(logits)\n","\n","      print(\"Top 2 actions:\")\n","      for j in np.argsort(probabilities)[::-1][:2]:\n","        print(f\"  {listed[j]:22}: {probabilities[j] * 100:2.2f}%\")\n","    predict(sample_video)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gx-gO-rjeEqH","executionInfo":{"status":"ok","timestamp":1673552501317,"user_tz":-330,"elapsed":156425,"user":{"displayName":"Aditya IIT Mandi","userId":"15697490575660665161"}},"outputId":"3b19c1e2-ed18-4690-a507-1132417d02aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 2 actions:\n","  answering questions   : 27.28%\n","  raising eyebrows      : 10.30%\n","Top 2 actions:\n","  lifting hat           : 38.13%\n","  tossing coin          : 6.66%\n","Top 2 actions:\n","  playing squash or racquetball: 13.25%\n","  smoking               : 8.20%\n","Top 2 actions:\n","  adjusting glasses     : 8.86%\n","  photobombing          : 8.66%\n","Top 2 actions:\n","  answering questions   : 15.25%\n","  smoking               : 10.08%\n","Top 2 actions:\n","  answering questions   : 22.05%\n","  chewing gum           : 15.33%\n","Top 2 actions:\n","  raising eyebrows      : 60.21%\n","  shaving head          : 7.93%\n","Top 2 actions:\n","  trimming shrubs       : 86.46%\n","  weaving basket        : 7.78%\n","Top 2 actions:\n","  pumping gas           : 38.35%\n","  getting a tattoo      : 15.58%\n","Top 2 actions:\n","  applying cream        : 24.44%\n","  using inhaler         : 11.99%\n"]}]},{"cell_type":"code","source":["# SAD\n","path = \"/content/drive/MyDrive/Scomp/Visual/Dataset/Youtube Data/Sad\"\n","wav_files = glob.glob(path + \"/*.mp4\")\n","for i in wav_files:\n","    video_path= i\n","    sample_video = load_video(video_path)[:100]\n","    sample_video.shape\n","\n","    def predict(sample_video):\n","      # Add a batch axis to the sample video.\n","      model_input = tf.constant(sample_video, dtype=tf.float32)[tf.newaxis, ...]\n","\n","      logits = i3d(model_input)['default'][0]\n","      probabilities = tf.nn.softmax(logits)\n","\n","      print(\"Top 2 actions:\")\n","      for i in np.argsort(probabilities)[::-1][:2]:\n","        print(f\"  {listed[i]:22}: {probabilities[i] * 100:2.2f}%\")\n","   \n","    predict(sample_video)"],"metadata":{"id":"9-uk2GYFd7O9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673552683680,"user_tz":-330,"elapsed":177358,"user":{"displayName":"Aditya IIT Mandi","userId":"15697490575660665161"}},"outputId":"227c0a61-e7b3-4c63-fba8-3f8d37a0a64e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 2 actions:\n","  applying cream        : 42.16%\n","  scrubbing face        : 11.19%\n","Top 2 actions:\n","  using inhaler         : 21.34%\n","  smoking               : 14.39%\n","Top 2 actions:\n","  texting               : 32.69%\n","  looking at phone      : 18.64%\n","Top 2 actions:\n","  answering questions   : 20.37%\n","  attending conference  : 6.47%\n","Top 2 actions:\n","  using inhaler         : 35.05%\n","  applying cream        : 9.93%\n","Top 2 actions:\n","  putting on foundation : 19.56%\n","  scrubbing face        : 16.08%\n","Top 2 actions:\n","  playing ukulele       : 28.76%\n","  using inhaler         : 21.01%\n","Top 2 actions:\n","  crying                : 17.88%\n","  using inhaler         : 17.74%\n","Top 2 actions:\n","  using inhaler         : 6.83%\n","  answering questions   : 5.04%\n","Top 2 actions:\n","  giving or receiving award: 27.57%\n","  sneezing              : 8.92%\n"]}]},{"cell_type":"code","source":["# SURPRISE\n","\n","path = \"/content/drive/MyDrive/Scomp/Visual/Dataset/Youtube Data/Surprise\"\n","wav_files = glob.glob(path + \"/*.mp4\")\n","for i in wav_files:\n","\n","    video_path= i\n","    sample_video = load_video(video_path)[:100]\n","    sample_video.shape\n","\n","    def predict(sample_video):\n","      # Add a batch axis to the sample video.\n","      model_input = tf.constant(sample_video, dtype=tf.float32)[tf.newaxis, ...]\n","\n","      logits = i3d(model_input)['default'][0]\n","      probabilities = tf.nn.softmax(logits)\n","\n","      print(\"Top 2 actions:\")\n","      for i in np.argsort(probabilities)[::-1][:2]:\n","        print(f\"  {listed[i]:22}: {probabilities[i] * 100:2.2f}%\")\n","    predict(sample_video)"],"metadata":{"id":"y9G8qhtyduwX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673552844151,"user_tz":-330,"elapsed":156641,"user":{"displayName":"Aditya IIT Mandi","userId":"15697490575660665161"}},"outputId":"04ec55d8-ef0d-4fc7-a666-489b47cd6a5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 2 actions:\n","  changing gear in car  : 18.59%\n","  texting               : 7.79%\n","Top 2 actions:\n","  setting table         : 84.52%\n","  scrapbooking          : 4.01%\n","Top 2 actions:\n","  moving furniture      : 31.11%\n","  laying tiles          : 21.99%\n","Top 2 actions:\n","  tie dying             : 14.95%\n","  building cabinet      : 7.98%\n","Top 2 actions:\n","  hugging (not baby)    : 17.36%\n","  finger snapping       : 13.14%\n","Top 2 actions:\n","  opening door          : 77.03%\n","  opening refrigerator  : 4.60%\n","Top 2 actions:\n","  reading newspaper     : 29.48%\n","  delivering mail       : 21.73%\n","Top 2 actions:\n","  opening door          : 56.91%\n","  opening refrigerator  : 19.56%\n","Top 2 actions:\n","  skipping rope         : 32.73%\n","  photobombing          : 18.08%\n","Top 2 actions:\n","  cleaning windows      : 25.84%\n","  sanding floor         : 5.61%\n"]}]},{"cell_type":"code","source":["# ANGER\n","\n","path = \"/content/drive/MyDrive/Scomp/Visual/Dataset/Youtube Data/Anger\"\n","wav_files = glob.glob(path + \"/*.mp4\")\n","for i in wav_files:\n","    file_name = os.path.basename(i)\n","    pth=(os.path.splitext(file_name)[0])\n","    video_path= i\n","    sample_video = load_video(video_path)[:100]\n","    sample_video.shape\n","\n","    def predict(sample_video):\n","      # Add a batch axis to the sample video.\n","      model_input = tf.constant(sample_video, dtype=tf.float32)[tf.newaxis, ...]\n","\n","      logits = i3d(model_input)['default'][0]\n","      probabilities = tf.nn.softmax(logits)\n","\n","      print(\"Top 2 actions:\")\n","      for i in np.argsort(probabilities)[::-1][:2]:\n","        print(f\"  {listed[i]:22}: {probabilities[i] * 100:2.2f}%\")\n","    predict(sample_video)"],"metadata":{"id":"1lCxJicWdkcy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673553003690,"user_tz":-330,"elapsed":154754,"user":{"displayName":"Aditya IIT Mandi","userId":"15697490575660665161"}},"outputId":"4e5977ca-494d-4b40-84b8-fe20b9055386"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 2 actions:\n","  laughing              : 48.70%\n","  sneezing              : 11.81%\n","Top 2 actions:\n","  headbanging           : 60.50%\n","  air drumming          : 16.70%\n","Top 2 actions:\n","  skydiving             : 27.49%\n","  carving ice           : 14.45%\n","Top 2 actions:\n","  using bagging machine : 20.48%\n","  grinding meat         : 7.17%\n","Top 2 actions:\n","  arguing               : 82.51%\n","  shaking hands         : 2.31%\n","Top 2 actions:\n","  using segway          : 65.56%\n","  motorcycling          : 12.95%\n","Top 2 actions:\n","  attending conference  : 28.59%\n","  answering questions   : 12.85%\n","Top 2 actions:\n","  talking on cell phone : 15.58%\n","  texting               : 9.12%\n","Top 2 actions:\n","  talking on cell phone : 10.41%\n","  directing traffic     : 10.21%\n","Top 2 actions:\n","  using inhaler         : 41.18%\n","  trimming or shaving beard: 7.39%\n"]}]},{"cell_type":"code","source":["# NEUTRAL\n","\n","path = \"/content/drive/MyDrive/Scomp/Visual/Dataset/Youtube Data/Neutral\"\n","wav_files = glob.glob(path + \"/*.mp4\")\n","for i in wav_files:\n","    video_path= i\n","    sample_video = load_video(video_path)[:100]\n","    sample_video.shape\n","\n","    def predict(sample_video):\n","      # Add a batch axis to the sample video.\n","      model_input = tf.constant(sample_video, dtype=tf.float32)[tf.newaxis, ...]\n","\n","      logits = i3d(model_input)['default'][0]\n","      probabilities = tf.nn.softmax(logits)\n","\n","      print(\"Top 2 actions:\")\n","      for i in np.argsort(probabilities)[::-1][:2]:\n","        print(f\"  {listed[i]:22}: {probabilities[i] * 100:2.2f}%\")\n","\n","    predict(sample_video)"],"metadata":{"id":"HC9LKxMnOiac","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673553173882,"user_tz":-330,"elapsed":165292,"user":{"displayName":"Aditya IIT Mandi","userId":"15697490575660665161"}},"outputId":"cff699f1-67df-4e46-a046-5387bf027f7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 2 actions:\n","  using inhaler         : 28.90%\n","  presenting weather forecast: 10.33%\n","Top 2 actions:\n","  answering questions   : 19.38%\n","  sign language interpreting: 6.48%\n","Top 2 actions:\n","  massaging neck        : 24.13%\n","  trimming or shaving beard: 20.32%\n","Top 2 actions:\n","  answering questions   : 12.62%\n","  chewing gum           : 9.69%\n","Top 2 actions:\n","  answering questions   : 20.33%\n","  opening refrigerator  : 7.76%\n","Top 2 actions:\n","  presenting weather forecast: 67.45%\n","  making balloon shapes : 2.23%\n","Top 2 actions:\n","  trimming or shaving beard: 7.94%\n","  waving hand           : 6.50%\n","Top 2 actions:\n","  answering questions   : 13.64%\n","  using inhaler         : 11.03%\n","Top 2 actions:\n","  presenting weather forecast: 33.01%\n","  giving or receiving award: 8.15%\n","Top 2 actions:\n","  presenting weather forecast: 59.35%\n","  giving or receiving award: 21.86%\n"]}]}]}